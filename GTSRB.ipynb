{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KDZ7/ImageClassification-TensorFlow-DeepLearning/blob/main/GTSRB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4YioGcCWKo7f"
      },
      "source": [
        "# **Comminication entre l'API Kaggle et Google Colab**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZIjU9QqNPUrr"
      },
      "outputs": [],
      "source": [
        "output_dir      = '/content/drive/MyDrive/kaggle/work'\n",
        "output_dir_tmp  = '/content/tmp/work'\n",
        "dataset_dir_tmp = '/content/tmp/dataset'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1uys0z7C8AK"
      },
      "outputs": [],
      "source": [
        "ratio = 0.5 # %Images Training\n",
        "pixels = 48"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iljhCoJvPaMa"
      },
      "source": [
        "# **Repertoire permanent et temporaire**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDuq7ShD4dRi"
      },
      "outputs": [],
      "source": [
        "!pip install kaggle -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejrWWL4hBCia",
        "outputId": "2cb88665-845b-4815-9ef1-041791cce488"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k7dSzdKcCnh8"
      },
      "outputs": [],
      "source": [
        "!mkdir -p ~/.kaggle/ && cp '{output_dir}/../kaggle.json' ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYLiUr-UF4EB"
      },
      "outputs": [],
      "source": [
        "!kaggle datasets list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utfzOd9pM80r"
      },
      "outputs": [],
      "source": [
        "!mkdir -p '{dataset_dir_tmp}' && kaggle datasets download -d meowmeowmeowmeowmeow/gtsrb-german-traffic-sign -p '{dataset_dir_tmp}' && unzip -n {dataset_dir_tmp}/gtsrb-german-traffic-sign.zip -d '{dataset_dir_tmp}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1mf5rVbqvuW"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import h5py\n",
        "\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime\n",
        "\n",
        "import cv2\n",
        "from skimage.morphology import disk\n",
        "from skimage.util import img_as_ubyte\n",
        "from skimage.filters import rank\n",
        "from skimage import io, color, exposure, transform\n",
        "from tqdm import tqdm\n",
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFOPzDwiqvug"
      },
      "source": [
        "*Summary of dataset preparation. For more details visit* [here](https://gricad-gitlab.univ-grenoble-alpes.fr/talks/fidle/-/blob/master/GTSRB.Keras3/01-Preparation-of-data.ipynb?ref_type=heads)\n",
        "\n",
        "**Enhanced datasets**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K2nCuYeqvul"
      },
      "source": [
        "# **1. Preparation of datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wCrGHo7qvum"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(f'{dataset_dir_tmp}/Test.csv', header=0)\n",
        "display(df.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPsCVg6jqvun"
      },
      "source": [
        "# ***Usefull functions***\n",
        "**A nice function for reading a dataset from an index.csv file.\\\n",
        "Input: an intex.csv file\\\n",
        "Output: an array of images ans an array of corresponding labels**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IyJInESeqvun"
      },
      "outputs": [],
      "source": [
        "def read_csv_dataset(csv_file):\n",
        "    '''\n",
        "    Reads traffic sign data from German Traffic Sign Recognition Benchmark dataset.\n",
        "    Arguments:\n",
        "        csv filename :  Description file, Example /data/GTSRB/Train.csv\n",
        "    Returns:\n",
        "        x,y          :  np array of images, np array of corresponding labels\n",
        "    '''\n",
        "\n",
        "    path = os.path.dirname(csv_file)\n",
        "    name = os.path.basename(csv_file)\n",
        "\n",
        "    # ---- Read csv file\n",
        "    #\n",
        "    df = pd.read_csv(csv_file, header=0)\n",
        "\n",
        "    # ---- Get filenames and ClassIds\n",
        "    #\n",
        "    filenames = df['Path'].to_list()\n",
        "    y         = df['ClassId'].to_list()\n",
        "    x         = []\n",
        "\n",
        "    # ---- Read images\n",
        "    #\n",
        "    for filename in tqdm(filenames, desc='Loading Images', unit=' image'):\n",
        "        image=io.imread(f'{path}/{filename}')\n",
        "        x.append(image)\n",
        "\n",
        "    # ---- Return\n",
        "    #\n",
        "    return (np.array(x,dtype=object), np.array(y))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpDTFPpcqvuo"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train) = read_csv_dataset(f'{dataset_dir_tmp}/Train.csv')\n",
        "(x_test,  y_test)  = read_csv_dataset(f'{dataset_dir_tmp}/Test.csv')\n",
        "(x_meta,  y_meta)  = read_csv_dataset(f'{dataset_dir_tmp}/Meta.csv')\n",
        "\n",
        "# ---- Shuffle train set\n",
        "x_train, y_train = shuffle(x_train, y_train)\n",
        "\n",
        "# ---- Sort Meta\n",
        "combined = list(zip(x_meta, y_meta))\n",
        "combined.sort(key=lambda x: x[1])\n",
        "x_meta, y_meta = zip(*combined) # dÃ©zipper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HdSAAlwFqvup"
      },
      "outputs": [],
      "source": [
        "# ------ Global stuff\n",
        "print(\"x_train shape : \",x_train.shape)\n",
        "print(\"y_train shape : \",y_train.shape)\n",
        "print(\"x_test  shape : \",x_test.shape)\n",
        "print(\"y_test  shape : \",y_test.shape)\n",
        "print(\"x_meta  size  : \",len(x_meta))\n",
        "print(\"y_meta  size  : \",len(y_meta))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ffp0z9kqvuq"
      },
      "source": [
        "# **Show Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYWea1Wrqvur"
      },
      "outputs": [],
      "source": [
        "def show(\n",
        "    images,\n",
        "    targets,\n",
        "    figsize=(16, 8),\n",
        "    index_range=(1, 17),\n",
        "    subplot=(4, 4),\n",
        "    axis_onoff=\"off\",\n",
        "    cmap=None,\n",
        "):\n",
        "    plt.figure(figsize=figsize)\n",
        "    for i in range(*index_range):\n",
        "        plt.subplot(*subplot, i)\n",
        "        plt.imshow(images[i], cmap=cmap)\n",
        "        plt.title(targets[i])\n",
        "        plt.axis(axis_onoff)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    print(\"><\")\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4gvciJAxqvus"
      },
      "outputs": [],
      "source": [
        "show(x_meta, y_meta)\n",
        "show(x_train, y_train)\n",
        "show(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PaLbr2ueqvut"
      },
      "source": [
        "# **Enhancement cooking**\n",
        "**A nice function for preparing our data.Input: a set of images (numpy array)Output: a enhanced images, resized and reprocessed (numpy array)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ZxgfZntqvuu"
      },
      "outputs": [],
      "source": [
        "def images_enhancement(images, width=24, height=24, proc='RGB'):\n",
        "    '''\n",
        "    Resize and convert images - doesn't change originals.\n",
        "    input images must be RGBA or RGB.\n",
        "    Note : all outputs are fixed size numpy array of float32\n",
        "    args:\n",
        "        images :         images list\n",
        "        width,height :   new images size (24, 24)\n",
        "        mode :           RGB | RGB-HE | L | L-HE | L-LHE | L-CLAHE\n",
        "    return:\n",
        "        numpy array of enhanced images\n",
        "    '''\n",
        "    lz={ 'RGB':3, 'RGB-HE':3, 'L':1, 'L-HE':1, 'L-LHE':1, 'L-CLAHE':1}[proc]\n",
        "\n",
        "    out=[]\n",
        "\n",
        "    for img in tqdm(images, desc=\"Enhancing images\", unit=' image'):\n",
        "\n",
        "        # ---- if RGBA, convert to RGB\n",
        "        if img.shape[2]==4:\n",
        "            img=color.rgba2rgb(img)\n",
        "\n",
        "        # ---- Resize\n",
        "        img = transform.resize(img, (width, height))\n",
        "\n",
        "        # ---- RGB / Histogram Equalization\n",
        "        if proc=='RGB-HE':\n",
        "            hsv = color.rgb2hsv(img.reshape(width, height,3))\n",
        "            hsv[:, :, 2] = exposure.equalize_hist(hsv[:, :, 2])\n",
        "            img = color.hsv2rgb(hsv)\n",
        "\n",
        "        # ---- Grayscale\n",
        "        if proc=='L':\n",
        "            img=color.rgb2gray(img)\n",
        "\n",
        "        # ---- Grayscale / Histogram Equalization\n",
        "        if proc=='L-HE':\n",
        "            img=color.rgb2gray(img)\n",
        "            img=exposure.equalize_hist(img)\n",
        "\n",
        "        # ---- Grayscale / Local Histogram Equalization\n",
        "        if proc=='L-LHE':\n",
        "            img=color.rgb2gray(img)\n",
        "            img = img_as_ubyte(img)\n",
        "            img=rank.equalize(img, disk(10))/255.\n",
        "\n",
        "        # ---- Grayscale / Contrast Limited Adaptive Histogram Equalization (CLAHE)\n",
        "        if proc=='L-CLAHE':\n",
        "            img=color.rgb2gray(img)\n",
        "            img=exposure.equalize_adapthist(img)\n",
        "\n",
        "        # ---- Add image in list of list\n",
        "        out.append(img)\n",
        "\n",
        "    # ---- Reshape images\n",
        "    #     (-1, width,height,1) for L\n",
        "    #     (-1, width,height,3) for RGB\n",
        "    #\n",
        "    out = np.array(out, dtype='float32')\n",
        "    out = out.reshape(-1, width, height, lz)\n",
        "    return out"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7vUEFqpqvuw"
      },
      "source": [
        "# **To get an idea of the different recipes**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_PaqSnRqvux"
      },
      "outputs": [],
      "source": [
        "i = random.randint(0, len(x_train) - 32)\n",
        "x_samples = x_train[i : i + 32]\n",
        "y_samples = y_train[i : i + 32]\n",
        "\n",
        "# Dictionary\n",
        "datasets  = {}\n",
        "\n",
        "datasets['RGB']     = images_enhancement(x_samples, width=pixels, height=pixels, proc='RGB')\n",
        "datasets['RGB-HE']  = images_enhancement(x_samples, width=pixels, height=pixels, proc='RGB-HE')\n",
        "datasets['L']       = images_enhancement(x_samples, width=pixels, height=pixels, proc='L')\n",
        "datasets['L-HE']    = images_enhancement(x_samples, width=pixels, height=pixels, proc='L-HE')\n",
        "datasets['L-LHE']   = images_enhancement(x_samples, width=pixels, height=pixels, proc='L-LHE')\n",
        "datasets['L-CLAHE'] = images_enhancement(x_samples, width=pixels, height=pixels, proc='L-CLAHE')\n",
        "\n",
        "# Afficher les images pour chaque mÃ©thode de traitement\n",
        "for key, images in datasets.items():\n",
        "    show(images, y_samples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4yQZ4JGVqvuy"
      },
      "source": [
        "# **A function to save a dataset (h5 file)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzdeEodKqvuz"
      },
      "outputs": [],
      "source": [
        "def save_h5_dataset(x_train, y_train, x_test, y_test, x_meta,y_meta, filename):\n",
        "\n",
        "    directory = os.path.dirname(filename)\n",
        "    if not os.path.exists(directory):\n",
        "        os.makedirs(directory)\n",
        "\n",
        "    # ---- Create h5 file\n",
        "    with h5py.File(filename, \"w\") as f:\n",
        "        f.create_dataset(\"x_train\", data=x_train)\n",
        "        f.create_dataset(\"y_train\", data=y_train)\n",
        "        f.create_dataset(\"x_test\",  data=x_test)\n",
        "        f.create_dataset(\"y_test\",  data=y_test)\n",
        "        f.create_dataset(\"x_meta\",  data=x_meta)\n",
        "        f.create_dataset(\"y_meta\",  data=y_meta)\n",
        "\n",
        "    # ---- done\n",
        "    size=os.path.getsize(filename)/(2**20)\n",
        "    print('Dataset : {:24s}  shape : {:22s} size : {:6.1f} Mo   (saved)'.format(filename, str(x_train.shape),size))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FS5oPrKLqvu0"
      },
      "source": [
        "# **Generate enhanced datasets**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMonqMWKqvu1"
      },
      "outputs": [],
      "source": [
        "# ---- Size and processings\n",
        "# create datasets with images of size 24x24 pixels and 48x48 pixels.\n",
        "all_pixels= [pixels] # [24, 48, 96]\n",
        "\n",
        "all_proc=['RGB', 'RGB-HE', 'L', 'L-LHE', 'L-LHE', 'L-CLAHE']\n",
        "\n",
        "n_train = int(len(x_train) * ratio)\n",
        "n_test  = int(len(x_test) * ratio)\n",
        "\n",
        "print(f'ratio is : {ratio}')\n",
        "print(f'x_train length is : {n_train}')\n",
        "print(f'x_test  length is : {n_test}')\n",
        "print(f'output dir is     : {output_dir}\\n')\n",
        "\n",
        "for px in all_pixels:\n",
        "    for m in all_proc:\n",
        "        # ---- A nice dataset name\n",
        "        filename = f'{output_dir}/set-{px}x{px}-{m}.h5'\n",
        "        # ---- Enhancement\n",
        "        #      Note : x_train is a numpy array of python objects (images with <> sizes)\n",
        "        #             but images_enhancement() return a real array of float64 numpy (images with same size)\n",
        "        #             so, we can save it in nice h5 files\n",
        "        #\n",
        "        x_train_new = images_enhancement(x_train[:n_train], width=px, height=px, proc=m)\n",
        "        x_test_new  = images_enhancement(x_test[:n_test],   width=px, height=px, proc=m)\n",
        "        x_meta_new  = images_enhancement(x_meta,            width=px, height=px, proc='RGB')\n",
        "\n",
        "        # ---- Save\n",
        "        save_h5_dataset(x_train_new, y_train[:n_train], x_test_new, y_test[:n_test], x_meta_new, y_meta, filename)\n",
        "\n",
        "x_train_new, x_test_new=0, 0\n",
        "print('\\nDone.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kz0698Xlqvu2"
      },
      "source": [
        "# **Reload data to be sure *.h5**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVS0jjoWqvu3"
      },
      "outputs": [],
      "source": [
        "def read_dataset(path_dir, dataset_name):\n",
        "    '''\n",
        "    Reads h5 dataset\n",
        "    Args:\n",
        "        filename     : datasets filename\n",
        "        dataset_name : dataset name, without .h5\n",
        "    Returns:\n",
        "        x_train,y_train, x_test,y_test data, x_meta,y_meta\n",
        "    '''\n",
        "\n",
        "    # ---- Read dataset\n",
        "    #\n",
        "    filename = f'{path_dir}/{dataset_name}.h5'\n",
        "    with  h5py.File(filename,'r') as f:\n",
        "        x_train = f['x_train'][:]\n",
        "        y_train = f['y_train'][:]\n",
        "        x_test  = f['x_test'][:]\n",
        "        y_test  = f['y_test'][:]\n",
        "        x_meta  = f['x_meta'][:]\n",
        "        y_meta  = f['y_meta'][:]\n",
        "\n",
        "    # ---- Shuffle train set\n",
        "    x_train, y_train = shuffle(x_train, y_train)\n",
        "\n",
        "    print(\"Rescaled shape >>> in:\", x_train.shape, \" out:\", y_train.shape)\n",
        "    return (x_train, y_train), (x_test, y_test), (x_meta, y_meta)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7S9Qgj7qvu4"
      },
      "outputs": [],
      "source": [
        "dataset_name=f'set-{pixels}x{pixels}-RGB'\n",
        "(x_tmp, y_tmp), (_,_), (_,_) = read_dataset(output_dir, dataset_name)\n",
        "show(x_tmp, y_tmp)\n",
        "x_tmp, y_tmp=0, 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KcdPELjgqvu5"
      },
      "source": [
        "![TensorFlow_logo.svg](data:image/svg+xml;base64,PHN2ZyBpZD0iQXJ0d29yayIgeG1sbnM9Imh0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnIiB4bWxuczp4bGluaz0iaHR0cDovL3d3dy53My5vcmcvMTk5OS94bGluayIgdmlld0JveD0iMCAwIDY2OS4zNiA0MjcuOCI+PGRlZnM+PHN0eWxlPi5jbHMtMXtmaWxsOm5vbmU7fS5jbHMtMntjbGlwLXBhdGg6dXJsKCNjbGlwLXBhdGgpO30uY2xzLTN7ZmlsbDp1cmwoI2xpbmVhci1ncmFkaWVudCk7fS5jbHMtNHtjbGlwLXBhdGg6dXJsKCNjbGlwLXBhdGgtMik7fS5jbHMtNXtmaWxsOnVybCgjbGluZWFyLWdyYWRpZW50LTIpO30uY2xzLTZ7ZmlsbDojNDI1MDY2O308L3N0eWxlPjxjbGlwUGF0aCBpZD0iY2xpcC1wYXRoIj48cG9seWdvbiBjbGFzcz0iY2xzLTEiIHBvaW50cz0iNDAyIDExMi41OSAzMzcuNDcgNzUuNzIgMzM3LjQ3IDIyNi44NCAzNjMuMjUgMjExLjg4IDM2My4yNSAxNjkuMzYgMzgyLjcyIDE4MC42MyAzODIuNjEgMTUxLjU0IDM2My4yNSAxNDAuNDggMzYzLjI1IDEyMy41OSA0MDIuMDkgMTQ2LjAzIDQwMiAxMTIuNTkiLz48L2NsaXBQYXRoPjxsaW5lYXJHcmFkaWVudCBpZD0ibGluZWFyLWdyYWRpZW50IiB4MT0iMjYxLjE4IiB5MT0iMTUxLjEiIHgyPSI0MTkuNjUiIHkyPSIxNTEuMSIgZ3JhZGllbnRVbml0cz0idXNlclNwYWNlT25Vc2UiPjxzdG9wIG9mZnNldD0iMCIgc3RvcC1jb2xvcj0iI2ZmNmYwMCIvPjxzdG9wIG9mZnNldD0iMSIgc3RvcC1jb2xvcj0iI2ZmYTgwMCIvPjwvbGluZWFyR3JhZGllbnQ+PGNsaXBQYXRoIGlkPSJjbGlwLXBhdGgtMiI+PHBvbHlnb24gY2xhc3M9ImNscy0xIiBwb2ludHM9IjI2Ny4xNCAxMTIuNTkgMzMxLjY3IDc1LjcyIDMzMS42NyAyMjYuODQgMzA1Ljg5IDIxMS44OCAzMDUuODkgMTIzLjU5IDI2Ny4wNSAxNDYuMDMgMjY3LjE0IDExMi41OSIvPjwvY2xpcFBhdGg+PGxpbmVhckdyYWRpZW50IGlkPSJsaW5lYXItZ3JhZGllbnQtMiIgeDE9IjI2MC4xMSIgeTE9IjE1MS4xIiB4Mj0iNDE4LjU4IiB5Mj0iMTUxLjEiIHhsaW5rOmhyZWY9IiNsaW5lYXItZ3JhZGllbnQiLz48L2RlZnM+PHRpdGxlPkZ1bGxDb2xvclByaW1hcnkgVmVydGljYWw8L3RpdGxlPjxnIGNsYXNzPSJjbHMtMiI+PHJlY3QgY2xhc3M9ImNscy0zIiB4PSIyNjEuMTgiIHk9Ijc1LjE3IiB3aWR0aD0iMTU4LjQ3IiBoZWlnaHQ9IjE1MS44NiIvPjwvZz48ZyBjbGFzcz0iY2xzLTQiPjxyZWN0IGNsYXNzPSJjbHMtNSIgeD0iMjYwLjExIiB5PSI3NS4xNyIgd2lkdGg9IjE1OC40NyIgaGVpZ2h0PSIxNTEuODYiLz48L2c+PHBhdGggY2xhc3M9ImNscy02IiBkPSJNMTM3LjMyLDI4Ny42SDExNHY2NC4yM0gxMDEuMTVWMjg3LjZINzguMDdWMjc3LjE0aDU5LjI1WiIvPjxwYXRoIGNsYXNzPSJjbHMtNiIgZD0iTTE1Mi43NywzNTIuODVxLTExLjg1LDAtMTkuMjEtNy40NnQtNy4zNi0xOS44OFYzMjRhMzMuNCwzMy40LDAsMCwxLDMuMi0xNC44NSwyNC40LDI0LjQsMCwwLDEsOS0xMC4xOCwyMy43NiwyMy43NiwwLDAsMSwxMi45Mi0zLjY0cTExLjM0LDAsMTcuNTIsNy4yM1QxNzUsMzIzdjVIMTM4Ljc2cS41Nyw2Ljg5LDQuNiwxMC44OGExMy43NiwxMy43NiwwLDAsMCwxMC4xMyw0QTE2Ljg5LDE2Ljg5LDAsMCwwLDE2Ny40NCwzMzZsNi43Miw2LjQxYTIyLjQxLDIyLjQxLDAsMCwxLTguOSw3LjcyQTI3Ljg0LDI3Ljg0LDAsMCwxLDE1Mi43NywzNTIuODVabS0xLjQ5LTQ3LjU1YTEwLjQ5LDEwLjQ5LDAsMCwwLTguMjgsMy41OXEtMy4xNywzLjU4LTQsMTBoMjMuNzVWMzE4cS0uNDEtNi4yNS0zLjMzLTkuNDZBMTAuNDEsMTAuNDEsMCwwLDAsMTUxLjI4LDMwNS4zWiIvPjxwYXRoIGNsYXNzPSJjbHMtNiIgZD0iTTE5Ni4yNywyOTYuMzJsLjM2LDYuNDFhMjAsMjAsMCwwLDEsMTYuMTYtNy40M3ExNy4zNCwwLDE3LjY0LDE5Ljg1djM2LjY4SDIxOHYtMzZjMC0zLjUzLS43Ni02LjEzLTIuMjgtNy44M3MtNC0yLjU0LTcuNDctMi41NHEtNy41MywwLTExLjIzLDYuODN2MzkuNUgxODQuNTJWMjk2LjMyWiIvPjxwYXRoIGNsYXNzPSJjbHMtNiIgZD0iTTI3MC44OCwzMzYuNzVhNS42NCw1LjY0LDAsMCwwLTIuNzQtNS4wOHEtMi43NS0xLjc2LTkuMTEtMy4wOGE0Ni43OCw0Ni43OCwwLDAsMS0xMC42Mi0zLjM5cS05LjMzLTQuNTEtOS4zMy0xMy4wOGExNC43NCwxNC43NCwwLDAsMSw2LTEycTYuMDYtNC44MywxNS4zOS00LjgyLDkuOTQsMCwxNi4wOCw0LjkyQTE1LjYxLDE1LjYxLDAsMCwxLDI4Mi43MywzMTNIMjcwLjI3YTcuNjcsNy42NywwLDAsMC0yLjY3LTYsMTAuMjMsMTAuMjMsMCwwLDAtNy4wOC0yLjM5LDExLDExLDAsMCwwLTYuNjksMS45LDYsNiwwLDAsMC0yLjYsNS4wOCw1LjA2LDUuMDYsMCwwLDAsMi40Miw0LjQ2cTIuNCwxLjU5LDkuNzQsMy4yMWE0Ni4yMiw0Ni4yMiwwLDAsMSwxMS41MiwzLjg1LDE2LjI3LDE2LjI3LDAsMCwxLDYuMjEsNS4zNiwxMy42NCwxMy42NCwwLDAsMSwyLDcuNTksMTQuNDUsMTQuNDUsMCwwLDEtNi4yMSwxMi4xM3EtNi4xOSw0LjY1LTE2LjI2LDQuNjRhMjguNjYsMjguNjYsMCwwLDEtMTIuMTUtMi40NiwyMCwyMCwwLDAsMS04LjMxLTYuNzcsMTYsMTYsMCwwLDEtMy05LjI5aDEyLjExYTguNzcsOC43NywwLDAsMCwzLjMzLDYuOCwxMywxMywwLDAsMCw4LjE2LDIuMzlxNC45MiwwLDcuNDktMS44OEE1Ljc3LDUuNzcsMCwwLDAsMjcwLjg4LDMzNi43NVoiLz48cGF0aCBjbGFzcz0iY2xzLTYiIGQ9Ik0yODkuNTYsMzIzLjU2YTMyLjY2LDMyLjY2LDAsMCwxLDMuMjMtMTQuNywyMy41NCwyMy41NCwwLDAsMSw5LjA4LTEwLjA1LDI1LjYxLDI1LjYxLDAsMCwxLDEzLjQ0LTMuNTFxMTEuMjQsMCwxOC4yMyw3LjIzdDcuNTcsMTkuMThsLjA1LDIuOTNBMzMuMDcsMzMuMDcsMCwwLDEsMzM4LDMzOS4zMWEyMy4zOSwyMy4zOSwwLDAsMS05LDEwLDI1Ljc4LDI1Ljc4LDAsMCwxLTEzLjU3LDMuNTRxLTExLjc1LDAtMTguOC03LjgydC03LjA1LTIwLjg1Wk0zMDIsMzI0LjY0cTAsOC41NywzLjU0LDEzLjQxYTExLjQ5LDExLjQ5LDAsMCwwLDkuODUsNC44NSwxMS4zNywxMS4zNywwLDAsMCw5LjgyLTQuOTJxMy41Mi00Ljk0LDMuNTItMTQuNDIsMC04LjQyLTMuNjItMTMuMzRhMTIuMTksMTIuMTksMCwwLDAtMTkuNTItLjA3UTMwMiwzMTUsMzAyLDMyNC42NFoiLz48cGF0aCBjbGFzcz0iY2xzLTYiIGQ9Ik0zNzguNjYsMzA3LjcxYTMxLjE2LDMxLjE2LDAsMCwwLTUuMDctLjQxcS04LjU4LDAtMTEuNTUsNi41N3YzOEgzNDkuNThWMjk2LjMyaDExLjlsLjMxLDYuMjFxNC41MS03LjIzLDEyLjUxLTcuMjNhMTEuODMsMTEuODMsMCwwLDEsNC40MS43MVoiLz48cGF0aCBjbGFzcz0iY2xzLTYiIGQ9Ik00MzAuNzgsMzIwLjE4SDQwMC43MnYzMS42NWgtMTNWMjc3LjE0aDQ3LjQ1VjI4Ny42SDQwMC43MnYyMi4yMWgzMC4wNloiLz48cGF0aCBjbGFzcz0iY2xzLTYiIGQ9Ik00NTUuNDEsMzUxLjgzSDQ0Mi45NFYyNzdoMTIuNDdaIi8+PHBhdGggY2xhc3M9ImNscy02IiBkPSJNNDY0LjU0LDMyMy41NmEzMi43OSwzMi43OSwwLDAsMSwzLjIzLTE0LjcsMjMuNiwyMy42LDAsMCwxLDkuMDgtMTAuMDUsMjUuNjEsMjUuNjEsMCwwLDEsMTMuNDQtMy41MXExMS4yMywwLDE4LjI0LDcuMjN0Ny41NywxOS4xOGwwLDIuOTNBMzIuOTMsMzIuOTMsMCwwLDEsNTEzLDMzOS4zMWEyMy4yNiwyMy4yNiwwLDAsMS05LDEwLDI1LjcyLDI1LjcyLDAsMCwxLTEzLjU2LDMuNTRxLTExLjc2LDAtMTguODEtNy44MnQtNy0yMC44NVpNNDc3LDMyNC42NHEwLDguNTcsMy41NCwxMy40MWExMi4zNCwxMi4zNCwwLDAsMCwxOS42Ny0uMDdxMy41MS00Ljk0LDMuNTEtMTQuNDIsMC04LjQyLTMuNjEtMTMuMzRhMTEuNTYsMTEuNTYsMCwwLDAtOS44My00LjkyLDExLjQzLDExLjQzLDAsMCwwLTkuNjksNC44NVE0NzcsMzE1LDQ3NywzMjQuNjRaIi8+PHBhdGggY2xhc3M9ImNscy02IiBkPSJNNTcyLjQsMzM0LjY0bDguODItMzguMzJoMTIuMTZsLTE1LjEzLDU1LjUxSDU2OGwtMTEuOS0zOC4xMi0xMS43LDM4LjEySDUzNC4xM0w1MTksMjk2LjMyaDEyLjE2bDksMzcuOTEsMTEuMzktMzcuOTFoOS4zOVoiLz48L3N2Zz4=)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_c6GNDgXxijq"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "epochs = 10\n",
        "optimizer=tf.keras.optimizers.Adam()\n",
        "loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "accurracy=tf.keras.metrics.SparseCategoricalAccuracy()\n",
        "dataset_name = f'set-{pixels}x{pixels}-RGB'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mKQ_5-ECxjcV"
      },
      "outputs": [],
      "source": [
        "!mkdir -p '{output_dir_tmp}' && cp '{output_dir}/{dataset_name}.h5' '{output_dir_tmp}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d_0fhxNGqvu6"
      },
      "outputs": [],
      "source": [
        "(x_train, y_train), (x_test, y_test), (x_meta, y_meta) = read_dataset(output_dir_tmp, dataset_name)\n",
        "\n",
        "print(\"x_train shape : \", x_train.shape)\n",
        "print(\"y_train shape : \", y_train.shape)\n",
        "print(\"x_test  shape : \", x_test.shape)\n",
        "print(\"y_test  shape : \", y_test.shape)\n",
        "\n",
        "show(x_train, y_train)\n",
        "show(x_test, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UmI9qMqeqvu7"
      },
      "source": [
        "# *Normalisation*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuzcZ2zKqvu7"
      },
      "outputs": [],
      "source": [
        "# x_train /= 255.0\n",
        "# x_test  /= 255.0\n",
        "print(\"x_train shape : \", x_train.shape)\n",
        "print(\"x_train_max   : \", x_train.max())\n",
        "print(\"x_train_mean  : \", x_train.mean())\n",
        "print(\"x_train_std   : \", x_train.std())\n",
        "print(\"x_test_max    : \", x_test.max())\n",
        "print(\"x_test_mean   : \", x_test.mean())\n",
        "print(\"x_test_std    : \", x_test.std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nKd07RrbnsYP"
      },
      "outputs": [],
      "source": [
        "class CustomModel(tf.keras.Model):\n",
        "    def __init__(self, input_shape):\n",
        "      super(CustomModel, self).__init__()\n",
        "\n",
        "      self._input_shape  = input_shape\n",
        "      self._00_CNN_Layer = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu)\n",
        "      self._01_CNN_Layer = tf.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation=tf.nn.relu)\n",
        "      self._00_Pooling   = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "      self._00_Dropout   = tf.keras.layers.Dropout(0.25)\n",
        "\n",
        "      self._02_CNN_Layer = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=tf.nn.relu)\n",
        "      self._03_CNN_Layer = tf.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation=tf.nn.relu)\n",
        "      self._01_Pooling   = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "      self._01_Dropout   = tf.keras.layers.Dropout(0.25)\n",
        "\n",
        "      self._04_CNN_Layer = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=tf.nn.relu)\n",
        "      self._05_CNN_Layer = tf.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation=tf.nn.relu)\n",
        "      self._02_Pooling   = tf.keras.layers.MaxPool2D(pool_size=(2, 2))\n",
        "      self._02_Dropout   = tf.keras.layers.Dropout(0.25)\n",
        "\n",
        "      self._00_Flatten   =  tf.keras.layers.Flatten()\n",
        "      self._00_Dense     =  tf.keras.layers.Dense(1024, activation=tf.nn.relu)\n",
        "      self._01_Dense     =  tf.keras.layers.Dense(512, activation=tf.nn.relu)\n",
        "      self._03_Dropout   =  tf.keras.layers.Dropout(0.25)\n",
        "      self._02_Dense     =  tf.keras.layers.Dense(43, activation=tf.nn.softmax)\n",
        "\n",
        "    def call_as_eagle(self, inputs, training=False):\n",
        "      x = self._00_CNN_Layer(inputs)\n",
        "      x = self._01_CNN_Layer(x)\n",
        "      x = self._00_Pooling(x)\n",
        "      x = self._00_Dropout(x, training=training)\n",
        "\n",
        "      x = self._02_CNN_Layer(x)\n",
        "      x = self._03_CNN_Layer(x)\n",
        "      x = self._01_Pooling(x)\n",
        "      x = self._01_Dropout(x, training=training)\n",
        "\n",
        "      x = self._04_CNN_Layer(x)\n",
        "      x = self._05_CNN_Layer(x)\n",
        "      x = self._02_Pooling(x)\n",
        "      x = self._02_Dropout(x, training=training)\n",
        "\n",
        "      x = self._00_Flatten(x)\n",
        "      x = self._00_Dense(x)\n",
        "      x = self._01_Dense(x)\n",
        "      x = self._03_Dropout(x, training=training)\n",
        "      x = self._02_Dense(x)\n",
        "      return x\n",
        "\n",
        "    def model(self):\n",
        "      x = tf.keras.Input(shape=self._input_shape)\n",
        "      return tf.keras.Model(inputs=x, outputs=self.call_as_eagle(inputs=x))\n",
        "\n",
        "    @tf.function\n",
        "    def call(self, inputs, training=False):\n",
        "      x = self._00_CNN_Layer(inputs)\n",
        "      x = self._01_CNN_Layer(x)\n",
        "      x = self._00_Pooling(x)\n",
        "      x = self._00_Dropout(x, training=training)\n",
        "\n",
        "      x = self._02_CNN_Layer(x)\n",
        "      x = self._03_CNN_Layer(x)\n",
        "      x = self._01_Pooling(x)\n",
        "      x = self._01_Dropout(x, training=training)\n",
        "\n",
        "      x = self._04_CNN_Layer(x)\n",
        "      x = self._05_CNN_Layer(x)\n",
        "      x = self._02_Pooling(x)\n",
        "      x = self._02_Dropout(x, training=training)\n",
        "\n",
        "      x = self._00_Flatten(x)\n",
        "      x = self._00_Dense(x)\n",
        "      x = self._01_Dense(x)\n",
        "      x = self._03_Dropout(x, training=training)\n",
        "      x = self._02_Dense(x)\n",
        "      return x\n",
        "\n",
        "    @tf.function\n",
        "    def train_step(self, data):\n",
        "        # Unpack the data. Its structure depends on your model and\n",
        "        # on what you pass to `fit()`.\n",
        "        x, y = data\n",
        "\n",
        "        with tf.GradientTape() as tape:\n",
        "            y_pred = self(x, training=True)  # Forward pass\n",
        "            # Compute the loss value\n",
        "            # (the loss function is configured in `compile()`)\n",
        "            loss = self.compiled_loss(y, y_pred, regularization_losses=self.losses)\n",
        "\n",
        "        # Compute gradients\n",
        "        trainable_vars = self.trainable_variables\n",
        "        gradients = tape.gradient(loss, trainable_vars)\n",
        "        # Update weights\n",
        "        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n",
        "        # Update metrics (includes the metric that tracks the loss)\n",
        "        self.compiled_metrics.update_state(y, y_pred)\n",
        "        # Return a dict mapping metric names to current value\n",
        "        return {m.name: m.result() for m in self.metrics}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ikriJmmDqvu8"
      },
      "outputs": [],
      "source": [
        "model = CustomModel(input_shape=(pixels, pixels, 3))\n",
        "model.model().summary()\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(), loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cQBA0i67JI_"
      },
      "source": [
        "# *Config Tensorboard*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PVny0tT7FT3"
      },
      "outputs": [],
      "source": [
        "log_dir = f\"{output_dir_tmp}/logs/fit/\" + datetime.now().strftime(\"%Y-%m-%d_%H:%M\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4szr68lXmQ9U"
      },
      "outputs": [],
      "source": [
        "history = model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs = epochs,\n",
        "    batch_size = batch_size,\n",
        "    validation_data = (x_test, y_test),\n",
        "    callbacks=[tensorboard_callback]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yr2g9x978x61"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir {output_dir_tmp}/logs/fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NM-0Ioq1qvu_"
      },
      "outputs": [],
      "source": [
        "loss = history.history[\"loss\"]\n",
        "acc = history.history[\"accuracy\"]\n",
        "\n",
        "val_loss = history.history[\"val_loss\"]\n",
        "val_acc = history.history[\"val_accuracy\"]\n",
        "\n",
        "plt.title(\"Loss\")\n",
        "plt.plot(loss, label=\"loss\")\n",
        "plt.plot(val_loss, label=\"val_loss\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()\n",
        "\n",
        "plt.title(\"Accuracy\")\n",
        "plt.plot(acc, label=\"acc\")\n",
        "plt.plot(val_acc, label=\"val_acc\")\n",
        "plt.legend(loc=\"upper left\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SpBoJ77OuFh"
      },
      "source": [
        "# **Show predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NmjebrjpOm58"
      },
      "outputs": [],
      "source": [
        "pred = np.argmax(model.predict(x_test), axis=1)\n",
        "show(x_test, pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lj6XEovePkMq"
      },
      "source": [
        "# **Show errors**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dAwWHg23PjeE"
      },
      "outputs": [],
      "source": [
        "# GÃ©nÃ©rer la liste des indices d'erreurs\n",
        "error_index = [i for i in range(len(x_test)) if pred[i] != y_test[i]]\n",
        "\n",
        "# Obtenir les images en erreur\n",
        "error_x_test = x_test[error_index]\n",
        "\n",
        "# Obtenir les prÃ©dictions correspondantes aux images d'erreur\n",
        "error_predictions = pred[error_index]\n",
        "\n",
        "print(\"nombre d'erreurs trouvÃ©es:\", len(error_index))\n",
        "show(error_x_test, error_predictions, cmap=\"plasma\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pK1EVxfPqvvA"
      },
      "source": [
        "# Save model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YtGWD5ROqvvB"
      },
      "outputs": [],
      "source": [
        "datetime_format = datetime.now().strftime('%Y-%m-%d_%H-%M')\n",
        "model.save(f'{output_dir}/model_{datetime_format}', save_format='tf')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "datasetId": 82373,
          "sourceId": 191501,
          "sourceType": "datasetVersion"
        }
      ],
      "dockerImageVersionId": 30664,
      "isGpuEnabled": false,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}